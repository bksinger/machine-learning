{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from numpy.linalg import inv, norm\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting and standardizing dataset\n",
    "dataset = datasets.load_breast_cancer()\n",
    "dataset_X = dataset.data[:, np.newaxis, 2]\n",
    "dataset_X_sd = (dataset_X - np.mean(dataset_X, axis=0))/np.std(dataset_X, axis=0)#Standardization is necssary\n",
    "#to avoid numerical stability issues \n",
    "dataset_Y = dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002360887023496673 seconds\n",
      "It took  0.002360887023496673 seconds to run\n",
      "beta =  [0.61894342] [[-3.57333075]]\n",
      "Error (cross entropy) =  152.94402381477659\n",
      "Error (sum of squares) =  46.972067614299064\n"
     ]
    }
   ],
   "source": [
    "tic = time.clock()\n",
    "n = len(dataset_Y)\n",
    "log_reg = linear_model.LogisticRegression()\n",
    "log_reg.fit (dataset_X_sd, dataset_Y)\n",
    "toc = time.clock()\n",
    "print(toc-tic, \"seconds\")\n",
    "beta = [log_reg.intercept_, log_reg.coef_]\n",
    "\n",
    "dataset_Y_hat = log_reg.predict_proba(dataset_X_sd)[:,1]\n",
    "\n",
    "epsilon = 1e-10\n",
    "error_cross_entropy = 0\n",
    "for i in range(n):\n",
    "    if dataset_Y[i] == 0:\n",
    "        error_cross_entropy -= np.log(1 - dataset_Y_hat[i] + epsilon)\n",
    "    else:\n",
    "        error_cross_entropy -= np.log(dataset_Y_hat[i] + epsilon)\n",
    "error_ss = np.sum((dataset_Y - dataset_Y_hat)**2)\n",
    "\n",
    "print(\"It took \", toc-tic, \"seconds to run\")\n",
    "print(\"beta = \", beta[0], beta[1])\n",
    "print(\"Error (cross entropy) = \", error_cross_entropy)\n",
    "print(\"Error (sum of squares) = \", error_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Derivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary preparations\n",
    "dataset_X_all = np.concatenate((np.ones((dataset_X_sd.shape[0], 1)), dataset_X_sd), axis=1)\n",
    "m = dataset_X_all.shape[1]\n",
    "dataset_Y = dataset_Y.reshape(n, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achieved convergence at iteration 7\n",
      "It took  0.00573984731666366 seconds to run\n",
      "beta =  [0.63169989] [-3.98118813]\n",
      "Error (cross entropy) =  [152.24219665]\n",
      "Error (sum of squares) =  46.91191116341832\n"
     ]
    }
   ],
   "source": [
    "#Newton-Raphson Cross Entropy Loss Minimization --> Note: Not always stable\n",
    "tic = time.clock()\n",
    "\n",
    "iter_max = 10\n",
    "beta = np.random.randn(m, 1)\n",
    "\n",
    "tolerance = 1e-10\n",
    "for t in range(iter_max):\n",
    "    beta_old = deepcopy(beta)\n",
    "    px = 1 / (1 + np.exp(-dataset_X_all @ beta_old))\n",
    "    one_minus_px = np.ones(px.shape) - px\n",
    "    eta = inv((px*dataset_X_all).T @ (one_minus_px*dataset_X_all))\n",
    "    beta += eta @ dataset_X_all.T @ (dataset_Y - px)\n",
    "    \n",
    "    #print(\"beta=\", beta[0], beta[1])\n",
    "    if norm(beta-beta_old) < tolerance:\n",
    "        print(\"Achieved convergence at iteration {}\".format(t))\n",
    "        break\n",
    "\n",
    "dataset_Y_hat = 1 / (1 + np.exp(-dataset_X_all @ beta))\n",
    "\n",
    "epsilon = 1e-10\n",
    "error_cross_entropy = 0\n",
    "for i in range(n):\n",
    "    if dataset_Y[i] == 0:\n",
    "        error_cross_entropy -= np.log(1 - dataset_Y_hat[i] + epsilon)\n",
    "    else:\n",
    "        error_cross_entropy -= np.log(dataset_Y_hat[i] + epsilon)\n",
    "error_ss = np.sum((dataset_Y - dataset_Y_hat)**2)\n",
    "\n",
    "toc = time.clock()\n",
    "\n",
    "print(\"It took \", toc-tic, \"seconds to run\")\n",
    "print(\"beta = \", beta[0], beta[1])\n",
    "print(\"Error (cross entropy) = \", error_cross_entropy)\n",
    "print(\"Error (sum of squares) = \", error_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achieved convergence at iteration 258\n",
      "It took  0.012988829243393951 seconds to run\n",
      "beta =  [0.63169989] [-3.98118813]\n",
      "Error (cross entropy) =  [152.24219665]\n",
      "Error (sum of squares) =  46.91191116341832\n"
     ]
    }
   ],
   "source": [
    "#Gradient Descent Cross Entropy Loss Minimization -- Matrix Version (faster than scalar version)\n",
    "tic = time.clock()\n",
    "\n",
    "iter_max = 1000\n",
    "beta = np.random.randn(m,1)\n",
    "eta = 0.01\n",
    "\n",
    "tolerance = 1e-10\n",
    "for t in range(iter_max):\n",
    "    beta_old = deepcopy(beta)\n",
    "    px = 1 / (1 + np.exp(-dataset_X_all @ beta_old))\n",
    "    beta += eta * dataset_X_all.T @ (dataset_Y - px)\n",
    "    \n",
    "    #print(\"beta = \", beta[0], beta[1])\n",
    "    if norm(beta-beta_old) < tolerance:\n",
    "        print(\"Achieved convergence at iteration {}\".format(t))\n",
    "        break\n",
    "\n",
    "epsilon = 1e-10\n",
    "error_cross_entropy = 0\n",
    "for i in range(n):\n",
    "    if dataset_Y[i] == 0:\n",
    "        error_cross_entropy -= np.log(1 - dataset_Y_hat[i] + epsilon)\n",
    "    else:\n",
    "        error_cross_entropy -= np.log(dataset_Y_hat[i] + epsilon)\n",
    "error_ss = np.sum((dataset_Y - dataset_Y_hat)**2)\n",
    "\n",
    "toc = time.clock()\n",
    "print(\"It took \", toc-tic, \"seconds to run\")\n",
    "print(\"beta = \", beta[0], beta[1])\n",
    "print(\"Error (cross entropy) = \", error_cross_entropy)\n",
    "print(\"Error (sum of squares) = \", error_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achieved convergence at iteration 257\n",
      "It took  2.462316276688373 seconds to run\n",
      "beta =  [0.63169989] [-3.98118813]\n",
      "Error (cross entropy) =  [152.24219665]\n",
      "Error (sum of squares) =  46.91191116341832\n"
     ]
    }
   ],
   "source": [
    "#Gradient Descent Cross Entropy Loss Minimization -- Scalar Version (slower than matrix version)\n",
    "tic = time.clock()\n",
    "\n",
    "iter_max = 1000\n",
    "beta = np.random.randn(m,1)\n",
    "eta = 0.01\n",
    "\n",
    "tolerance = 1e-10\n",
    "for t in range(iter_max):\n",
    "    beta_old = deepcopy(beta)\n",
    "    \n",
    "    for j in range(m):\n",
    "        s = 0\n",
    "        for i in range(n):\n",
    "            px = 1 / (1 + np.exp(-dataset_X_all[i,:] @ beta_old))\n",
    "            s += (dataset_Y[i] - px)* dataset_X_all[i,j]\n",
    "        beta[j] += eta*s\n",
    "    \n",
    "    #print(\"beta = \", beta[0], beta[1])\n",
    "    if norm(beta-beta_old) < tolerance:\n",
    "        print(\"Achieved convergence at iteration {}\".format(t))\n",
    "        break\n",
    "\n",
    "epsilon = 1e-10\n",
    "error_cross_entropy = 0\n",
    "for i in range(n):\n",
    "    if dataset_Y[i] == 0:\n",
    "        error_cross_entropy -= np.log(1 - dataset_Y_hat[i] + epsilon)\n",
    "    else:\n",
    "        error_cross_entropy -= np.log(dataset_Y_hat[i] + epsilon)\n",
    "error_ss = np.sum((dataset_Y - dataset_Y_hat)**2)\n",
    "\n",
    "toc = time.clock()\n",
    "print(\"It took \", toc-tic, \"seconds to run\")\n",
    "print(\"beta = \", beta[0], beta[1])\n",
    "print(\"Error (cross entropy) = \", error_cross_entropy)\n",
    "print(\"Error (sum of squares) = \", error_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took  0.04402880471798021 seconds to run\n",
      "beta =  [0.67575093] [-3.90046724]\n",
      "Error (cross entropy) =  [152.24219665]\n",
      "Error (sum of squares) =  46.91191116341832\n"
     ]
    }
   ],
   "source": [
    "#Gradient Descent Sum of Least Squares Minimization -- Matrix Version\n",
    "tic = time.clock()\n",
    "\n",
    "iter_max = 1000\n",
    "beta = np.random.randn(m,1)\n",
    "eta = 0.01\n",
    "\n",
    "tolerance = 1e-10\n",
    "for t in range(iter_max):\n",
    "    beta_old = deepcopy(beta)\n",
    "    px = 1 / (1 + np.exp(-dataset_X_all @ beta_old))\n",
    "    one_minus_px = np.ones(px.shape) - px\n",
    "    beta += eta * dataset_X_all.T @ ((dataset_Y - px) * px * one_minus_px)\n",
    "    \n",
    "    #print(\"beta = \", beta[0], beta[1])\n",
    "    if norm(beta-beta_old) < tolerance:\n",
    "        print(\"Achieved convergence at iteration {}\".format(t))\n",
    "        break\n",
    "\n",
    "epsilon = 1e-10\n",
    "error_cross_entropy = 0\n",
    "for i in range(n):\n",
    "    if dataset_Y[i] == 0:\n",
    "        error_cross_entropy -= np.log(1 - dataset_Y_hat[i] + epsilon)\n",
    "    else:\n",
    "        error_cross_entropy -= np.log(dataset_Y_hat[i] + epsilon)\n",
    "error_ss = np.sum((dataset_Y - dataset_Y_hat)**2)\n",
    "\n",
    "toc = time.clock()\n",
    "print(\"It took \", toc-tic, \"seconds to run\")\n",
    "print(\"beta = \", beta[0], beta[1])\n",
    "print(\"Error (cross entropy) = \", error_cross_entropy)\n",
    "print(\"Error (sum of squares) = \", error_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
